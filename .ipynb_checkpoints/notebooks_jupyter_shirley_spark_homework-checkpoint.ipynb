{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from google.cloud import storage\n",
    "from scipy.sparse import coo_matrix\n",
    "import pyspark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading json files from the bucket "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_name = \"bgse-datawarehousing-random-tweets\"\n",
    "\n",
    "storage_client = storage.Client()\n",
    "bucket = storage_client.bucket(bucket_name)\n",
    "\n",
    "json_file_list = []\n",
    "for blob in bucket.list_blobs():\n",
    "    json_file_list.append(\"gs://bgse-datawarehousing-random-tweets\" + \"/\" + blob.name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'gs://bgse-datawarehousing-random-tweets/2019-02-26T00:00:30.657Z'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_file_list[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_df = spark.read.json(json_file_list)\n",
    "#json_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting Hashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, lower, size\n",
    "from itertools import combinations\n",
    "\n",
    "def lowercase_list(lst):\n",
    "    return list(map(lambda item: item.lower(), lst))\n",
    "\n",
    "def identity(x):\n",
    "    return x\n",
    "\n",
    "hashtags = (\n",
    "    json_df\n",
    "        .select(\"entities.hashtags.text\")\n",
    "        # filter out any rows without more than one hashtag\n",
    "        .where(size(col(\"text\")) > 1)\n",
    "        .limit(10)\n",
    "        .rdd\n",
    "        # select the text from the rows\n",
    "        .map(lambda r: r['text'])\n",
    "        # lowercase all the hashtags\n",
    "        .map(lowercase_list)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[18] at RDD at PythonRDD.scala:52"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'france',\n",
       " u'ford',\n",
       " u'happy_taeyang_day',\n",
       " u'narcissus',\n",
       " u'\\uc608\\ubed0\\uc9c0\\uc9c0\\ub9c8',\n",
       " u'\\ud0dc\\uc591',\n",
       " u'\\uc720\\ud0dc\\uc591',\n",
       " u'taeyang',\n",
       " u'sf9\\ud0dc\\uc591',\n",
       " u'\\u30c6\\u30e4\\u30f3',\n",
       " u'nowplaying',\n",
       " u'onairnow',\n",
       " u'edm',\n",
       " u'redvelvet',\n",
       " u'\\ub808\\ub4dc\\ubca8\\ubcb3',\n",
       " u'redvelvet_redmare',\n",
       " u'redvelvet_redmareinusa',\n",
       " u'redvelvet_redmareincanada',\n",
       " u'\\uc9c4\\uc601',\n",
       " u'\\ubc15\\uc9c4\\uc601',\n",
       " u'got7',\n",
       " u'\\uc0ac\\uc774\\ucf54\\uba54\\ud2b8\\ub9ac\\uadf8\\ub140\\uc11d',\n",
       " u'redvelvet',\n",
       " u'seulgi',\n",
       " u'\\ub808\\ub4dc\\ubca8\\ubcb3',\n",
       " u'\\uc2ac\\uae30',\n",
       " u'pinkmarket',\n",
       " u'eiikleaw',\n",
       " u'mamamoo',\n",
       " u'\\ub9c8\\ub9c8\\ubb34',\n",
       " u'\\ud558\\uc796\\uc544_\\ub9c8\\ub9c8\\ubb34_\\ucef4\\ubc31',\n",
       " u'twbdimash',\n",
       " u'worldsbest',\n",
       " u'nailagda',\n",
       " u'notebook']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sometimes there is more than one hashtag so we have a list of lists\n",
    "#use flatmap to reduce it all into one list\n",
    "hashtags.flatMap(identity).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting combinations of every hashtag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pair_combinations(lst):\n",
    "    return combinations(lst, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashtag_combinations = (\n",
    "    hashtags.flatMap(pair_combinations)\n",
    "        .map(lambda tup: (tup, 1))\n",
    "        .countByKey()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'news', u'justdoit', 1),\n",
       " (u'justdoit', u'oscar2019', 1),\n",
       " (u'haraam', u'brexit', 1),\n",
       " (u'supportsmallstreamers', u'justdoit', 1),\n",
       " (u'snowday', u'teamgodvek', 1),\n",
       " (u'comedy', u'teamgodvek', 1),\n",
       " (u'oscars', u'snowday', 1),\n",
       " (u'oscar2019', u'teamgodvek', 1),\n",
       " (u'trump', u'hanoi', 1),\n",
       " (u'comedy', u'news', 1),\n",
       " (u'news', u'supportsmallstreamers', 1),\n",
       " (u'comedy', u'supportsmallstreamers', 1),\n",
       " (u'comedy', u'snowday', 1),\n",
       " (u'disgusting', u'notlegal', 1),\n",
       " (u'halal', u'food', 1),\n",
       " (u'talk', u'oscar2019', 1),\n",
       " (u'oscar2019', u'twitch', 1),\n",
       " (u'comedy', u'oscars', 1),\n",
       " (u'talk', u'teamgodvek', 1),\n",
       " (u'trump', u'humantrafficking', 1),\n",
       " (u'twitch', u'teamgodvek', 1),\n",
       " (u'talk', u'comedy', 1),\n",
       " (u'sosprisiones', u'tuabandonomepuedematar', 1),\n",
       " (u'oscar2019', u'snowday', 1),\n",
       " (u'news', u'oscars', 1),\n",
       " (u'justdoit', u'oscars', 1),\n",
       " (u'lechuguinos', u'25feb', 1),\n",
       " (u'halal', u'haraam', 1),\n",
       " (u'comedy', u'twitch', 1),\n",
       " (u'halal', u'brexit', 1),\n",
       " (u'president', u'hanoi', 1),\n",
       " (u'music', u'snowday', 1),\n",
       " (u'music', u'supportsmallstreamers', 1),\n",
       " (u'northkorea', u'kimjongun', 1),\n",
       " (u'talk', u'oscars', 1),\n",
       " (u'talk', u'justdoit', 1),\n",
       " (u'president', u'trump', 1),\n",
       " (u'trump', u'kimjongun', 1),\n",
       " (u'music', u'oscars', 1),\n",
       " (u'oscars', u'teamgodvek', 1),\n",
       " (u'talk', u'music', 1),\n",
       " (u'president', u'kimjongun', 1),\n",
       " (u'talk', u'twitch', 1),\n",
       " (u'supportsmallstreamers', u'oscars', 1),\n",
       " (u'hanoi', u'kimjongun', 1),\n",
       " (u'justdoit', u'snowday', 1),\n",
       " (u'oscar2019', u'oscars', 1),\n",
       " (u'supportsmallstreamers', u'teamgodvek', 1),\n",
       " (u'talk', u'snowday', 1),\n",
       " (u'music', u'justdoit', 1),\n",
       " (u'twitch', u'snowday', 1),\n",
       " (u'supportsmallstreamers', u'oscar2019', 1),\n",
       " (u'comedy', u'oscar2019', 1),\n",
       " (u'comedy', u'music', 1),\n",
       " (u'talk', u'supportsmallstreamers', 1),\n",
       " (u'food', u'brexit', 1),\n",
       " (u'news', u'snowday', 1),\n",
       " (u'music', u'news', 1),\n",
       " (u'news', u'teamgodvek', 1),\n",
       " (u'justdoit', u'teamgodvek', 1),\n",
       " (u'trump', u'northkorea', 1),\n",
       " (u'emergency', u'potus', 1),\n",
       " (u'nicollewallace', u'trump', 1),\n",
       " (u'news', u'oscar2019', 1),\n",
       " (u'hanoi', u'northkorea', 1),\n",
       " (u'comedy', u'justdoit', 1),\n",
       " (u'news', u'twitch', 1),\n",
       " (u'justdoit', u'twitch', 1),\n",
       " (u'haraam', u'food', 1),\n",
       " (u'supportsmallstreamers', u'snowday', 1),\n",
       " (u'supportsmallstreamers', u'twitch', 1),\n",
       " (u'music', u'oscar2019', 1),\n",
       " (u'talk', u'news', 1),\n",
       " (u'oscars', u'twitch', 1),\n",
       " (u'music', u'teamgodvek', 1),\n",
       " (u'president', u'northkorea', 1),\n",
       " (u'music', u'twitch', 1),\n",
       " (u'leadership', u'democrats', 1)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def flatten_dict(d):\n",
    "    return [(x, y, z) for ((x, y), z) in d.items()]\n",
    "\n",
    "flattened_dict = flatten_dict(hashtag_combinations)\n",
    "flattened_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating both halves of matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "key1, key2, count = zip(*flattened_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "matrix_first_half = flattened_dict\n",
    "matrix_second_half = list(zip(key2,key1,count))\n",
    "matrix_first_half + matrix_second_half"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "key1, key2, count = zip(*matrix_first_half + matrix_second_half)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "key1 = list(key1)\n",
    "key2 = list(key2)\n",
    "count = list(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking the matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(u'justdoit', u'oscars', 1)\n",
      "(u'lechuguinos', u'25feb', 1)\n",
      "(u'halal', u'haraam', 1)\n",
      "(u'comedy', u'twitch', 1)\n",
      "(u'halal', u'brexit', 1)\n"
     ]
    }
   ],
   "source": [
    "for i in flattened_dict[25:30]:\n",
    "    print(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(u'justdoit', u'oscars', 1)\n",
      "(u'lechuguinos', u'25feb', 1)\n",
      "(u'halal', u'haraam', 1)\n",
      "(u'comedy', u'twitch', 1)\n",
      "(u'halal', u'brexit', 1)\n"
     ]
    }
   ],
   "source": [
    "for i in range(25,30):\n",
    "    print(key1[i], key2[i], count[i])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Taking my dictionary and making a sparse matrix from it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<32x32 sparse matrix of type '<type 'numpy.int64'>'\n",
       "\twith 156 stored elements in COOrdinate format>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'key1': key1, 'key2': key2, 'count': count})\n",
    "df.set_index(['key1', 'key2'], inplace=True)\n",
    "matrix = coo_matrix((df['count'],(df.index.labels[0], df.index.labels[1])))\n",
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 1],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 1, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
