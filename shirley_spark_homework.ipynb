{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "\n",
    "from google.cloud import storage\n",
    "from scipy.sparse import coo_matrix\n",
    "\n",
    "import pyspark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading json files from the bucket "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_name = \"bgse-datawarehousing-random-tweets\"\n",
    "\n",
    "storage_client = storage.Client()\n",
    "bucket = storage_client.bucket(bucket_name)\n",
    "\n",
    "json_file_list = []\n",
    "for blob in bucket.list_blobs():\n",
    "    json_file_list.append(\"gs://\" + bucket_name + \"/\" + blob.name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6109"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(json_file_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_df = spark.read.json(json_file_list[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting Hashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, lower, size\n",
    "from itertools import combinations\n",
    "\n",
    "def lowercase_list(lst):\n",
    "    return list(map(lambda item: item.lower(), lst))\n",
    "\n",
    "hashtags = (\n",
    "    json_df\n",
    "        .select(\"entities.hashtags.text\")\n",
    "        # filter out any rows without more than one hashtag\n",
    "        .where(size(col(\"text\")) > 1)\n",
    "        .rdd\n",
    "        # select the text from the rows\n",
    "        .map(lambda r: r['text'])\n",
    "        # lowercase all the hashtags\n",
    "        .map(lowercase_list)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[15] at RDD at PythonRDD.scala:52"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hashtags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting combinations of every hashtag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pair_combinations(lst):\n",
    "    return combinations(lst, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashtag_combinations = (\n",
    "    hashtags.flatMap(pair_combinations)\n",
    "        .map(lambda tup: (tup, 1))\n",
    "        .countByKey()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def flatten_dict(d):\n",
    "    return [(x, y, z) for ((x, y), z) in d.items()]\n",
    "\n",
    "flattened_dict = flatten_dict(hashtag_combinations)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating both halves of matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "key1, key2, count = zip(*flattened_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "matrix_first_half = flattened_dict\n",
    "matrix_second_half = list(zip(key2,key1,count))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "key1, key2, count = zip(*matrix_first_half + matrix_second_half)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "key1 = list(key1)\n",
    "key2 = list(key2)\n",
    "count = list(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking the matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(u'leftwing', u'blair', 47)\n",
      "(u'usa', u'us', 2)\n",
      "(u'marxist', u'bbc', 1)\n",
      "(u'followme', u'pussy', 1)\n",
      "(u'trump', u'nasdaq', 1)\n"
     ]
    }
   ],
   "source": [
    "for i in flattened_dict[25:30]:\n",
    "    print(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(u'leftwing', u'blair', 47)\n",
      "(u'usa', u'us', 2)\n",
      "(u'marxist', u'bbc', 1)\n",
      "(u'followme', u'pussy', 1)\n",
      "(u'trump', u'nasdaq', 1)\n"
     ]
    }
   ],
   "source": [
    "for i in range(25,30):\n",
    "    print(key1[i], key2[i], count[i])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Taking my dictionary and making a sparse matrix from it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1791x1791 sparse matrix of type '<type 'numpy.int64'>'\n",
       "\twith 11272 stored elements in COOrdinate format>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'key1': key1, 'key2': key2, 'count': count})\n",
    "df.set_index(['key1', 'key2'], inplace=True)\n",
    "matrix = coo_matrix((df['count'],(df.index.labels[0], df.index.labels[1])))\n",
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.sparse.save_npz('sparse_matrix.npz', matrix, compressed=True)\n",
    "sparse_matrix = scipy.sparse.load_npz('sparse_matrix.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1791x1791 sparse matrix of type '<type 'numpy.int64'>'\n",
       "\twith 11272 stored elements in COOrdinate format>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparse_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}